Help on Elevator in module pyRDDLGym.Elevator object:

class Elevator(gym.core.Env)
 |  Elevator(is_render=False, render_path='temp_vis', instance=4)
 |  
 |  Method resolution order:
 |      Elevator
 |      gym.core.Env
 |      typing.Generic
 |      builtins.object
 |  
 |  Methods defined here:
 |  
 |  __init__(self, is_render=False, render_path='temp_vis', instance=4)
 |      Discrete version of the Elevator example. Please do not modify this
 |  
 |  action2disc(self, original_action)
 |  
 |  convert_to_Prob_matrix(self, P1, P2)
 |  
 |  disc2action(self, a)
 |      Converts discrete action into Elevator environment
 |      Input:
 |          - a (int): action
 |      Return:
 |          - a (definition): action that is compatible with Elevator environment
 |  
 |  disc2state(self, s)
 |      Converts discrete state into Elevator environment state
 |      Input:
 |          - s (int): action
 |      Return:
 |          - s (definition): state that is compatible with Elevator environment
 |  
 |  find_state(self, s, context)
 |  
 |  init_actions(self)
 |      Initializes discrete actions
 |  
 |  init_states(self)
 |      Initializes discrete states
 |  
 |  render(self)
 |      Compute the render frames as specified by render_mode attribute during initialization of the environment.
 |      
 |      The set of supported modes varies per environment. (And some
 |      third-party environments may not support rendering at all.)
 |      By convention, if render_mode is:
 |      
 |      - None (default): no render is computed.
 |      - human: render return None.
 |        The environment is continuously rendered in the current display or terminal. Usually for human consumption.
 |      - rgb_array: return a single frame representing the current state of the environment.
 |        A frame is a numpy.ndarray with shape (x, y, 3) representing RGB values for an x-by-y pixel image.
 |      - rgb_array_list: return a list of frames representing the states of the environment since the last reset.
 |        Each frame is a numpy.ndarray with shape (x, y, 3), as with `rgb_array`.
 |      - ansi: Return a strings (str) or StringIO.StringIO containing a
 |        terminal-style text representation for each time step.
 |        The text can include newlines and ANSI escape sequences (e.g. for colors).
 |      
 |      Note:
 |          Make sure that your class's metadata 'render_modes' key includes
 |          the list of supported modes. It's recommended to call super()
 |          in implementations to use the functionality of this method.
 |  
 |  reset(self, seed=None)
 |      Resets the environment to an initial state and returns the initial observation.
 |      
 |      This method can reset the environment's random number generator(s) if ``seed`` is an integer or
 |      if the environment has not yet initialized a random number generator.
 |      If the environment already has a random number generator and :meth:`reset` is called with ``seed=None``,
 |      the RNG should not be reset. Moreover, :meth:`reset` should (in the typical use case) be called with an
 |      integer seed right after initialization and then never again.
 |      
 |      Args:
 |          seed (optional int): The seed that is used to initialize the environment's PRNG.
 |              If the environment does not already have a PRNG and ``seed=None`` (the default option) is passed,
 |              a seed will be chosen from some source of entropy (e.g. timestamp or /dev/urandom).
 |              However, if the environment already has a PRNG and ``seed=None`` is passed, the PRNG will *not* be reset.
 |              If you pass an integer, the PRNG will be reset even if it already exists.
 |              Usually, you want to pass an integer *right after the environment has been initialized and then never again*.
 |              Please refer to the minimal example above to see this paradigm in action.
 |          options (optional dict): Additional information to specify how the environment is reset (optional,
 |              depending on the specific environment)
 |      
 |      
 |      Returns:
 |          observation (object): Observation of the initial state. This will be an element of :attr:`observation_space`
 |              (typically a numpy array) and is analogous to the observation returned by :meth:`step`.
 |          info (dictionary):  This dictionary contains auxiliary information complementing ``observation``. It should be analogous to
 |              the ``info`` returned by :meth:`step`.
 |  
 |  save_render(self)
 |  
 |  state2disc(self, original_state)
 |  
 |  step(self, action)
 |      Run one timestep of the environment's dynamics.
 |      
 |      When end of episode is reached, you are responsible for calling :meth:`reset` to reset this environment's state.
 |      Accepts an action and returns either a tuple `(observation, reward, terminated, truncated, info)`.
 |      
 |      Args:
 |          action (ActType): an action provided by the agent
 |      
 |      Returns:
 |          observation (object): this will be an element of the environment's :attr:`observation_space`.
 |              This may, for instance, be a numpy array containing the positions and velocities of certain objects.
 |          reward (float): The amount of reward returned as a result of taking the action.
 |          terminated (bool): whether a `terminal state` (as defined under the MDP of the task) is reached.
 |              In this case further step() calls could return undefined results.
 |          truncated (bool): whether a truncation condition outside the scope of the MDP is satisfied.
 |              Typically a timelimit, but could also be used to indicate agent physically going out of bounds.
 |              Can be used to end the episode prematurely before a `terminal state` is reached.
 |          info (dictionary): `info` contains auxiliary diagnostic information (helpful for debugging, learning, and logging).
 |              This might, for instance, contain: metrics that describe the agent's performance state, variables that are
 |              hidden from observations, or individual reward terms that are combined to produce the total reward.
 |              It also can contain information that distinguishes truncation and termination, however this is deprecated in favour
 |              of returning two booleans, and will be removed in a future version.
 |      
 |          (deprecated)
 |          done (bool): A boolean value for if the episode has ended, in which case further :meth:`step` calls will return undefined results.
 |              A done signal may be emitted for different reasons: Maybe the task underlying the environment was solved successfully,
 |              a certain timelimit was exceeded, or the physics simulation has entered an invalid state.
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes defined here:
 |  
 |  __annotations__ = {}
 |  
 |  __parameters__ = ()
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from gym.core.Env:
 |  
 |  __enter__(self)
 |      Support with-statement for the environment.
 |  
 |  __exit__(self, *args)
 |      Support with-statement for the environment.
 |  
 |  __str__(self)
 |      Returns a string of the environment with the spec id if specified.
 |  
 |  close(self)
 |      Override close in your subclass to perform any necessary cleanup.
 |      
 |      Environments will automatically :meth:`close()` themselves when
 |      garbage collected or when the program exits.
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from gym.core.Env:
 |  
 |  unwrapped
 |      Returns the base non-wrapped environment.
 |      
 |      Returns:
 |          Env: The base non-wrapped gym.Env instance
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from gym.core.Env:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
 |  
 |  np_random
 |      Returns the environment's internal :attr:`_np_random` that if not set will initialise with a random seed.
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from gym.core.Env:
 |  
 |  __orig_bases__ = (typing.Generic[~ObsType, ~ActType],)
 |  
 |  metadata = {'render_modes': []}
 |  
 |  render_mode = None
 |  
 |  reward_range = (-inf, inf)
 |  
 |  spec = None
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from typing.Generic:
 |  
 |  __class_getitem__(params) from builtins.type
 |  
 |  __init_subclass__(*args, **kwargs) from builtins.type
 |      This method is called when a class is subclassed.
 |      
 |      The default implementation does nothing. It may be
 |      overridden to extend subclasses.

